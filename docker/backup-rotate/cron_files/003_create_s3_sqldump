#!/usr/bin/env python3

"""
Create a SQL dump of the database
Compress it with gzip
Upload to S3 repository
"""

import os
import gzip
import subprocess
import datetime
import boto3


DB_HOST = os.getenv('DB_HOST')
DB_PASSWORD = os.getenv('DB_PASSWORD')
S3_ENDPOINT = os.getenv('S3_ENDPOINT')
S3_BUCKET = os.getenv('S3_BUCKET')
S3_ACCESS_KEY = os.getenv('S3_ACCESS_KEY')
S3_SECRET_KEY = os.getenv('S3_SECRET_KEY')
S3_PATH = os.getenv('S3_PATH')


def create_compressed_mysqldump(filename):
    cmd_sql = ["mysqldump", "--port=3306", f"--host={DB_HOST}",
               f"-p{DB_PASSWORD}", "--all-databases"]
    p1 = subprocess.Popen(cmd_sql,
                          stdout=subprocess.PIPE,
                          stderr=subprocess.STDOUT)
    dump_content = p1.communicate()[0]

    with gzip.open(filename, 'wb') as f:
        f.write(dump_content)


def upload_file_s3(filepath, filename):
    session = boto3.session.Session()
    client = session.client('s3',
                            endpoint_url=f'https://{S3_ENDPOINT}',
                            aws_access_key_id=S3_ACCESS_KEY,
                            aws_secret_access_key=S3_SECRET_KEY)

    client.upload_file(Filename=filepath,
                       Bucket=S3_BUCKET,
                       Key=f"{S3_PATH}/mysqldump/{filename}")


if __name__ == "__main__":
    print("Create MYSQLDUMP at S3")
    timestamp = datetime.datetime.now().strftime('%Y%m%dT%H%M%S')
    file_name = f"db_{timestamp}.sql.gz"
    file_path = f"/mysqldump/tmp_{file_name}"
    create_compressed_mysqldump(file_path)
    upload_file_s3(file_path, file_name)
    os.remove(file_path)
